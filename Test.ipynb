{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7vqfL1fDSaOmRM6In1Idu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Testing the DSAPM**"],"metadata":{"id":"DmVRkSI1Nezd"}},{"cell_type":"code","source":["# Initialization\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pandas as pd\n","import cv2\n","import os\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.models import load_model\n","from math import log10, sqrt\n","from sklearn import preprocessing\n","\n","# Load the DSAPM model\n","model = load_model(\"models/dsapm.h5\", compile=False)\n","\n","# Load the test data\n","all_images_test = []\n","im_dir = \"/content/drive/MyDrive/Test_Data\"\n","list_of_files = sorted(os.listdir(im_dir), reverse=False)\n","\n","for im_folder in list_of_files:\n","    list_of_img_files = sorted(os.listdir(os.path.join(im_dir, im_folder)), reverse=False)\n","    for image_file in list_of_img_files:\n","        image_path = os.path.join(im_dir, im_folder, image_file)\n","        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","        image = cv2.resize(image, (128, 128))\n","        all_images_test.append([image])\n","\n","# Ensure correct total images before reshaping\n","print(f\"Total images loaded: {len(all_images_test)}\")\n","\n","# Reshape test data into (360, 20, 128, 128, 1)\n","all_images_test = np.array(all_images_test).reshape(360, 20, 128, 128, 1)\n","\n","# Normalize the data\n","all_images_test = all_images_test / 255.0\n","\n","# Compute MSE\n","MSE = []\n","for j in range(360):\n","    example = all_images_test[j, :, :, :, :]\n","    frames = example[1:20, :, :, :, :]  # Input frames\n","    original_frames = example[:, :, :, :]  # Ground truth\n","\n","    new_prediction = model.predict(np.expand_dims(frames, axis=0))\n","    new_prediction = np.squeeze(new_prediction, axis=0)\n","    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n","\n","    frames = np.concatenate((frames, predicted_frame), axis=0)\n","    new_frames = frames[-1, :, :, :, :]\n","\n","    mse = np.square(np.subtract(new_frames, original_frames[1, :, :, :, :])).mean()\n","    MSE.append(mse)\n","\n","# Compute PSNR\n","max_pixel = 1.0\n","PSNR = [20 * log10(max_pixel / sqrt(mse)) if mse > 0 else 100 for mse in MSE]\n","\n","# Normalize PSNR\n","norm_PSNR_predicted = preprocessing.normalize([PSNR]).flatten()\n","PSNR_max, PSNR_min = max(norm_PSNR_predicted), min(norm_PSNR_predicted)\n","\n","# Compute Frame Score\n","Predicted_test = [(x - PSNR_min) / (PSNR_max - PSNR_min) for x in norm_PSNR_predicted]\n","\n","# Save Frame Scores\n","df_test = pd.DataFrame({\"Frame Score\": Predicted_test})\n","df_test.to_excel(\"frame_scores_test.xlsx\", index=False)\n","\n","# Load threshold value\n","file_path = \"frame_scores_train.xlsx\"\n","df_threshold = pd.read_excel(file_path)\n","\n","Fs_th = df_threshold[\"Threshold\"].iloc[0]\n","\n","# Apply Anomaly Detection\n","df_test[\"Anomaly_Status\"] = df_test[\"Frame Score\"].apply(lambda x: \"Normal\" if x > Fs_th else \"Anomalous\")\n","df_test.to_excel(\"frame_scores_test.xlsx\", index=False)\n","\n","\n"],"metadata":{"id":"6dFCZqBeNfG7"},"execution_count":null,"outputs":[]}]}