{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjtL6H5C5d5HweMcLDFG/M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Evaluation Metrics**"],"metadata":{"id":"V-PizfgqaOeY"}},{"cell_type":"code","source":["# Import necessary libraries\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import cv2\n","import glob\n","import os\n","from google.colab.patches import cv2_imshow\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score"],"metadata":{"id":"Sd80qiJuckYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify the path to the Excel file in Google Drive\n","\n","file_path = '/content/drive/MyDrive/Results.xlsx'\n","\n","# Load data from the Excel sheet. This data consists of the frame scores of test data which has both predicted values and actual values\n","\n","df = pd.read_excel(file_path, sheet_name='Dataset')\n","Actual = df['Actual'].to_numpy()\n","Predicted = df['Predicted'].to_numpy()"],"metadata":{"id":"UMiSgFqIaOxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix\n","threshold = 0.6\n","y_pred = (Predicted > threshold).astype(int)\n","\n","# Compute the confusion matrix\n","cm = confusion_matrix(Actual, y_pred)\n","\n","# Extract TP, TN, FP, FN\n","TN, FP, FN, TP = cm.ravel()\n","\n","# Print TP, TN, FP, FN\n","print(f\"True Positives (TP): {TP}\")\n","print(f\"True Negatives (TN): {TN}\")\n","print(f\"False Positives (FP): {FP}\")\n","print(f\"False Negatives (FN): {FN}\")\n","\n","# Calculate precision, recall, specificity and F1 score\n","precision = precision_score(Actual, y_pred)\n","recall = recall_score(Actual, y_pred)\n","f1 = f1_score(Actual, y_pred)\n","specificity = TN / (TN + FP)\n","\n","# Print the metrics\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","\n","# Update font properties with an alternative serif font\n","plt.rcParams.update({'font.size': 16, 'font.family': 'serif', 'font.serif': 'DejaVu Serif'})\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Purples\", cbar=True,\n","                 xticklabels=['Abnormal (0)', 'Normal (1)'],\n","                 yticklabels=['Abnormal (0)', 'Normal (1)'])\n","\n","# Set axis labels\n","plt.xlabel('Predicted Event', color='black')\n","plt.ylabel('Actual Event', color='black')\n","\n","# Set tick labels color to black\n","ax.tick_params(axis='both', colors='black')\n","\n","plt.title('Dataset', fontsize=16)\n","plt.show()\n"],"metadata":{"id":"4XdbNdE0aPWZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ROC\n","\n","plt.style.use('ggplot')\n","plt.rcParams[\"figure.figsize\"] = (16,9)\n","%matplotlib inline\n","\n","P = sum(Actual)\n","N = len(Actual) - P\n","FPR = []\n","TPR = []\n","# Iterate thresholds from 0.0 to 1.0\n","thresholds = np.arange(0.0, 1.01, 0.1)\n","# array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9. 1.0 ])\n","\n","# iterate through all thresholds and determine fraction of true positives\n","# and false positives found at this threshold\n","for thresh in thresholds:\n","    FP=0\n","    TP=0\n","    thresh = round(thresh,2)\n","    for i in range(len(Predicted)):\n","        if (Predicted[i] >= thresh):\n","            if Actual[i] == 1:\n","                TP = TP + 1\n","            if Actual[i] == 0:\n","                FP = FP + 1\n","    FPR.append(FP/N)\n","    TPR.append(TP/P)\n","print('TPR:', TPR)\n","print('FPR:', FPR)\n","\n","#AUC\n","auc = -1 * np.trapz(TPR, FPR)\n","\n","plt.plot(FPR, TPR, linestyle='--', marker='o', color='darkorange', lw = 2, label='Test_Dataset', clip_on=False)\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.0])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC curve; AUC = %.4f'%auc)\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"id":"4Zf-QaDBdxza"},"execution_count":null,"outputs":[]}]}